<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <title>Dashboard</title>
    <link rel="stylesheet" href="/static/style.css">
    <script src="/static/script.js" defer></script>
</head>
<body>
    <header>
        <h1>Dashboard roBERTa</h1>
    </header>
    <main>
        <div class="main" id="intro-container">
            <h2 class="intro-title">Bienvenue dans le tableau de bord</h2>
            <div class="intro-text">
                Ce tableau de bord à pour objectif de permettre à un public non averti de comprendre notre preuve de concept du modèle roBERTa.
            </div>
            <div class="intro-quote">
                "roBERTa est un modèle de langage naturel développé par Facebook AI, basé sur l'architecture transformer. Il est conçu pour améliorer la performance du modèle BERT en utilisant une formation plus poussée et des techniques d'optimisation supplémentaires, telles que l'exclusion de la prédiction de masque et l'entraînement sur des données supplémentaires non étiquetées."
            </div>
        </div>

        <div class="dropdown-predict">
            <h3 class="main-paragraph-title">
                ..mais d'abord, un exemple de prédiction de notre modèle entraîné : roBERTa
            </h3>
            <select id="options">
              <option value="It's officail. I'm sick  runny nose, soar throat, maaaajooor headache. uughh">It's officail. I'm sick  runny nose, soar throat, maaaajooor headache. uughh</option>
              <option value="I look forward to that the school is ended   It's very long !!">I look forward to that the school is ended   It's very long !!</option>
              <option value="Another week of being stuck with myself">Another week of being stuck with myself</option>
              <option value="@gigiamk30 I wish I weren't feeling tired I would go hunting for the guys LOL too bad">@gigiamk30 I wish I weren't feeling tired I would go hunting for the guys LOL too bad</option>
              <option value="@Yin_Yin so why do they make it soooo damn hard to buy one and install it? Not Happy">@Yin_Yin so why do they make it soooo damn hard to buy one and install it? Not Happy</option>
              <option value="damn it I just missed a call from other girl">damn it I just missed a call from other girl</option>
              <option value="I don't wanna go to sleep now, but I have to if I wanna be able to function at work tomorrow at 6 am">I don't wanna go to sleep now, but I have to if I wanna be able to function at work tomorrow at 6 am</option>
              <option value="No twitter, no phones, no TV... It will be a looong day">No twitter, no phones, no TV... It will be a looong day</option>
              <option value="My back hurts   I need a massage...">My back hurts   I need a massage...</option>
              <option value="Taking a walk, beautiful outside now that the sun came out">Taking a walk, beautiful outside now that the sun came out</option>
              <option value="I just played mario kart wii. haha its fun.">I just played mario kart wii. haha its fun.</option>
              <option value="@sick_nasty Awwww how nice! Happy birthday Mrs. Abercrombie!!!!">@sick_nasty Awwww how nice! Happy birthday Mrs. Abercrombie!!!!</option>
              <option value="@Shar_har_har Your love is amazing">@Shar_har_har Your love is amazing</option>
              <option value="going to the JFK graduation ceremony.  congrats seniors!">going to the JFK graduation ceremony.  congrats seniors!</option>
              <option value="-_- nah, I just saw him on tv and fell in love again">-_- nah, I just saw him on tv and fell in love again</option>
              <option value="@debnixon you're a simple woman with simple tastes">@debnixon you're a simple woman with simple tastes</option>
              <option value="hiding in the freezer at work eating cookie dough    --SLOANSTER--">hiding in the freezer at work eating cookie dough    --SLOANSTER--</option>
            </select>
            <button class="button_dropdown" id="submitBtn" onclick="predict_sentiment()">Prédire le sentiment</button>
            <div id="result"></div>
        </div>

        <div class="expandable-box">
            <input type="checkbox" id="toggle1">
            <label for="toggle1" class="box-header" id="box-header1">
                <h3 class="main-paragraph-title">
                    Présentation du Dataset<span class="documentation">Documentation</span>
                </h3>
              <span class="arrow" id="arrow1">&#9658;</span>
            </label>
            <div class="box-content" id="box-content1">
                <div class="main-paragraph-text">
                    Le dataset choisi pour réaliser notre travail de veille afin de trouver une méthode récente afin d’améliorer la performance d’un modèle est le fichier Sentiment140, un dataset de 1.6millions de tweet en anglais extrait de l’api de twitter durant la période du 17 Avril 2009 au 27 Mai 2009, lorsqu’elle était encore disponible. Les tweets ont été annoté (0 = négatif, 4 = positif) et peuvent être utilisé pour prédire le sentiment du tweet.
                    <br>
                    <br>
                    <div>
                        
                    </div>
                    Le DataFrame est caractérisé par 6 variables :<br>
                    <ol>
                        <li>target: le sentiment du tweet</li>
                        <li>id: identifiant du tweet</li>
                        <li>date: date du tweet</li>
                        <li>flag: La requête (LyX). Si il n'y a pas de requête alors la valeur sera NO_QUERY</li>
                        <li>user: l'utilisateur qui a tweeté</li>
                        <li>text: le texte du tweet (avecLyX)</li>
                    </ol>
                    Pour simplifier au maximum notre étude et réaliser l’entraînement des différents modèles dans un temps restreint, nous avons décidé de réaliser un échantillon de 10.000 tweets plutôt que d’entraîner nos modèles sur la totalité des données. Les différentes classes sont distribuées de manière équilibré avec 5.000 tweets caractérisés comme positif et 5.000 tweets caractérisés comme négatif.
                    <br>
                    <br>
                    Un travail de pré-traitement à été effectué sur les données textuelles pour simplifier la compréhension de ces données, notamment la suppression des noms d’utilisateurs, des liens, des caractères numériques, etc.
                    <br>
                    <br>
                    L’objectif de cette entrainement est d’obtenir un modèle capable de prédire le sentiment positif ou négatif d’un tweet à partir de leur contenu textuel.
                </div>
            </div>
        </div>

        <div class="expandable-box">
            <input type="checkbox" id="toggle1bis">
            <label for="toggle1bis" class="box-header" id="box-header1bis">
                <h3 class="main-paragraph-title">
                    Nuage de mots<span class="graphical">Graphique</span>
                </h3>
                <span class="arrow" id="arrow1bis">&#9658;</span>
            </label>
            <div class="box-content" id="box-content1bis">
                <div class="main-paragraph-text">
                    Pour faciliter la compréhension du dataset, nous avons réalisé plusieurs visualisations graphiques permettant aux utilisateurs de contextualiser les données qui ont permis d'entraîner les différents modèles afin d'évaluer leurs performances.
                    <br>
                    <br>
                    Voici différents nuages de mot permettant de visualiser le sentiment des tweets selon leur label positif ou négatif.
                    <div class="main-paragraph-radio">
                        <input type="radio" name="image_choice1" value="image1" id="image1" onclick="display_cloudWords()" checked> 
                        <label class="radio-style" for="image1">Tweets Positifs</label>
                        <input type="radio" name="image_choice1" value="image2" id="image2" onclick="display_cloudWords()">
                        <label class="radio-style" for="image2">Tweets Négatifs</label>
                    </div>  
                    
                    <div class="main-paragraph-image">
                        <img src="./static/images/df_pos.png" alt="" id="main-paragraph-image-display_1">
                    </div>
                </div>
            </div>
        </div>

        <div class="expandable-box">
            <input type="checkbox" id="toggle1ter">
            <label for="toggle1ter" class="box-header" id="box-header1ter">
                <h3 class="main-paragraph-title">
                    Distribution des données<span class="graphical">Graphique</span>
                </h3>
                <span class="arrow" id="arrow1ter">&#9658;</span>
            </label>
            <div class="box-content" id="box-content1ter">
                <div class="main-paragraph-text">
                    Pour faciliter la compréhension du dataset, nous avons réalisé plusieurs visualisations graphiques permettant aux utilisateurs de contextualiser les données qui ont permis d'entraîner les différents modèles afin d'évaluer leurs performances.
                    <br>
                    <br>
                    Voici différentes visualisation de la distribution du nombre de mots par tweet selon leur label positif ou négatif.
                    <div class="main-paragraph-radio">
                        <input type="radio" name="image_choice2" value="image3" id="image3" onclick="display_cloudWords()" checked> 
                        <label class="radio-style" for="image3">Tweets Positifs</label>
                        <input type="radio" name="image_choice2" value="image4" id="image4" onclick="display_cloudWords()">
                        <label class="radio-style" for="image4">Tweets Négatifs</label>
                    </div>  
                    
                    <div class="main-paragraph-image">
                        <img src="../static/images/countX_pos.png" alt="" id="main-paragraph-image-display_2">
                    </div>

                </div>
            </div>
        </div>
        
          <div class="expandable-box">
            <input type="checkbox" id="toggle2">
            <label for="toggle2" id="box-header2" class="box-header">
                <h3 class="main-paragraph-title">
                    Concept de roBERTa <span class="documentation">Documentation</span>
                </h3>
              <span class="arrow" id="arrow2">&#9658;</span>
            </label>
            <div id="box-content2" class="box-content">
                <div class="main-paragraph-text">
                    RoBERTa n’est qu’une amélioration, une optimisation bien senti du modèle de base BERT. Il en reprend son nom, mais également toute son architecture. Il convient alors pour bien comprendre le fonctionnement du modèle roBERTa, de bien comprendre en amont le modèle BERT.
                    <br>
                    <br>
                    BERT est basé sur une architecture de réseau de neurones Transformer, une architecture introduite par Google (Vaswani et al. NeurIPS 2017) dans la publication « Attention Is All You Need ». Cette architecture est construite sur la base de différents couches d’attention.
                    <br>
                    <br>
                    BERT est entraîné sur des larges jeux de données textuelles non étiquetés notamment des livres non-publiés, des pages de Wikipédia ou d’autres sites internet. 
                    <br>
                    <br>
                    Durant son entrainement, BERT transforme les mots en token sur lesquels il applique une travail de compréhension pour ensuite les transmettre aux différentes couches du réseau de neurones par des représentations vectorielles. 
                    Dans ces différentes couches d’attention, BERT tente de comprendre le contexte de chaque mot en les analysant dans leur environnement.
                    Il utilise pour cela une méthode de masquage statique (Masked Language Model), pour masquer certains mots, puis essaie de les prédire en se basant sur le contexte des autres mots dans la phrase.
                    BERT utilise également une méthode de masquage de phrase suivante (Next Sentence Prediction) pour tenter de déterminer si une phrase en suit une autre dans un texte.
                    <br>
                    <br>
                    De cette manière, BERT arrive à capturer les relations et dépendances entre les mots à long terme dans un texte le tout de manière parallèle.
                    <br>
                    <br>
                    La principale caractéristique concernant roBERTa est son optimisation, il en tire d’ailleurs son nom, robustly optimized BERT approach. <br>
                    Nombreux sont les modèles LLMs qui permettent de réaliser différentes analyses sur des données textuelles et d’obtenir des résultats de performances extrêmement intéressants et encourageants, BERT en fait parti. <br>
                    L’élaboration du modèle roBERTa survient dans les faiblesses du modèle BERT.
                    <br>
                    <br>
                    En effet le modèle BERT a été entraîné sur un jeu de données relativement restreint (16gGB de texte), et son hyper-paramétrage n’a pas forcément bien été évalué pour maximiser ses performances.
                    <br>
                    <br>
                    RoBERTa propose de pallier à ces lacunes en entraînant le modèle plus longtemps, avec des lots de données plus important et également sur beaucoup plus de données. 
                    <br>
                    <br>
                    BERT utilise une tâche d'apprentissage appelée "Next Sentence Prediction" (NSP) pour son entraînement. RoBERTa ne prend pas en compte cette tâche afin d’améliorer les performances d’apprentissage, en assimilant plus facilement les relations entre les mots et les phrases.
                    <br>
                    <br>
                    Enfin, BERT, utilise une méthode de masquage statique (MLM), les mêmes tokens sont masqués à chaque itération. RoBERTa utilise une technique appelée "dynamic masking» qui comme son nom l’indique, modifie dynamiquement les masques d’apprentissages à chaque itération du modèle pour lui permettre de mieux généraliser ses prédictions.
                    <br>
                    <br>
                    RoBERTa représente une évolution signification de BERT, tirant parti de son architecture de base tout en introduisant des optimisations essentielles ce qui nous permettra d’améliorer notre travail de classification de sentiments sur le dataset de tweets.
                </div>
            </div>
          </div>

          <div class="expandable-box">
            <input type="checkbox" id="toggle3">
            <label for="toggle3" class="box-header" id="box-header3">
                <h3 class="main-paragraph-title">
                    Modélisation <span class="documentation">Documentation</span>
                </h3>
              <span class="arrow" id="arrow3">&#9658;</span>
            </label>
            <div class="box-content" id="box-content3">
                <div class="main-paragraph-text">
                    RoBERTa est un langage pré-entraîné qui reprend l’architecture du modèle BERT auquel il apporte différentes améliorations et optimisations pour parvenir à de meilleurs résultats.
                    <br>
                    <br>
                    RoBERTa a donc été entrainé différemment de BERT, en utilisant une tâche d'apprentissage automatique appelée Masked Language Model (MLM), en supprimant la méthode de masquage de phrase suivante (Next Sentence Prediction) et enfin, en multipliant par 10 les données de son entraînement.
                    <br>
                    <br>
                    La possibilité de ré-entrainement sur nos propres données du modèle BERT et roBERTa nous permettra de tester par nous même l’évolution de performance des différents modèles.
                    <br>
                    <br>
                    Dans l’étude sur laquelle nous nous appuyons, la méthode d’évaluation du modèle a été effectué grâce à 3 exercices d’évaluations différents, The General Language Understanding Evaluation (GLUE), The Stanford Question Answering Dataset (SQuAD), et enfin The ReAding Comprehension from Ex-aminations (RACE).
                    <br>
                    <br>
                    Notre méthode d’évaluation ne se fera pas sur des exercices de classification de modèles, mais sur des métriques sélectionnées en fonction de la problématique sur laquelle nous entrainerons les modèles à savoir, la classification de sentiments binaire.
                    <br>
                    <br>
                    Pour cela nous utiliserons différentes métriques :
                    <ul>
                        <li>
                            le F1 Score : mesure de précision d'un modèle de classification binaire, elle est calculé en prenant la moyenne harmonique de la précision et du rappel.
                        </li>
                        <li>
                            la courbe ROC : graphique utilisé pour évaluer la performance d'un modèle de classification binaire
                        </li>
                    </ul>
                    Mais avant de commencer ce travail d’évaluation il est important de préciser le traitement effectué sur les données afin de les faire correspondre au mieux à ce qu’attend en entrée les différents modèles.
                    <br>
                    <br>
                    Nous avons réalisé différents nettoyage du jeu de donnée pour simplifier la compréhension de l’interprétation du sentiment binaire des tweets, a savoir :
                    <ul>
                        <li>
                            la suppression des identifiants d’utilisateurs
                        </li>
                        <li>
                            la suppression des liens internet
                        </li>
                        <li>
                            la suppression des caractères qui ne sont pas alphanumériques
                        </li>
                        <li>
                            la suppression  des mots composés d’un seul caractère (utilisé pour les smiley)
                        </li>
                        <li>
                            la suppression des caractères numériques
                        </li>
                        <li>
                            la conversion de tous les caractères en minuscule
                        </li>
                        <li>
                            la lemmatization (trouver la racine) de tous les verbes et adjectifs
                        </li>
                        <li>
                            la suppression de tous les stop-words (mot récurent n’apportant pas 			d’information supplémentaire à la compréhension).
                        </li>
                    </ul>
                    Nous diviserons nos données en 3. Un premier set d’entrainement, un set de validation qui permet d’évaluer et d’ajuster l’apprentissage du modèle durant son entrainement, et enfin, un set de test, qui nous permettra d’évaluer la performance des différents modèles en fonction des métriques que nous avons sélectionné.
                </div>
            </div>
          </div>

          <div class="expandable-box">
            <input type="checkbox" id="toggle4">
            <label for="toggle4" class="box-header" id="box-header4">
                <h3 class="main-paragraph-title">
                    Synthèse des résultats <span class="documentation">Documentation</span>
                </h3>
              <span class="arrow" id="arrow4">&#9658;</span>
            </label>
            <div class="box-content" id="box-content4">
                <div class="main-paragraph-text">
                    Il est désormais temps de présenter la performance des différents modèles. 
                    <br>
                    <br>
                    Grâce à notre utilisation de Mlflow Tracking et des différentes métriques sélectionnés nous avons des résultats à étudier et commenter.
                    <br>
                    <br>
                    Le F1 score combine à la fois la précision (capacité du modèle à ne pas classer à tort un exemple positif comme négatif) et le rappel (capacité du modèle à identifier tous les exemples positifs). 
                    <br>
                    Une valeur de F1 score proche de 1 indique un modèle très performant, tandis qu'une valeur proche de 0 indique une performance médiocre.
                    <br>
                    <br>
                    Nous pouvons constater que le modèle roBERTa obtiens un meilleur score 0.89 que le modèle BERT 0.81.
                    <br>
                    En effet, grâce à son entraînement sur de plus large jeu de données et de plus nombreuses séquences d’itération roBERTa réussi à capturer des informations contextuelles plus fines et donc permettre une meilleure classification de sentiments sur des données textuelles.
                    <br>
                    <br>
                    Quant à la courbe ROC (Receiver Operating Characteristic), c’est un outil visuelle
                    permettant d’évaluer la performance d’un classification binaire. En effet, elle fait
                    apparaître le taux de vrais positifs en fonction du taux de faux positifs.
                    Nous pouvons résumer la performance de nos modèles en mesurant l’air sous la
                    courbe ROC. Une valeur de 1 aura pour signification un modèle qui ne fait jamais
                    d’erreur. <br>
                    Ici, les valeurs pour nos différents modèles sont respectivement de 0.91 pour
                    roBERTa et 0.88 pour BERT.
                    <br>
                    <br>
                    En conclusion, les résultats indiquent que roBERTa surpasse BERT en termes de performance, comme en témoigne son F1 Score et AUC plus élevés. Cependant, le choix entre ces deux modèles devrait également prendre en considération des facteurs tels que la disponibilité des ressources de calculs et les exigences spécifiques de la tâche à accomplir.
                </div>
            </div>
          </div>

          <div class="expandable-box">
            <input type="checkbox" id="toggle5">
            <label for="toggle5" class="box-header" id="box-header5">
                <h3 class="main-paragraph-title">
                    Courbe ROC <span class="graphical">Graphique</span>
                </h3>
              <span class="arrow" id="arrow5">&#9658;</span>
            </label>
            <div class="box-content" id="box-content5">
                <div class="main-paragraph-text">
                    La courbe ROC (Receiver Operating Characteristic) est un graphique qui illustre la performance d'un modèle de classification binaire à différents seuils de décision.
                    <br>
                    <br>
                    Sur l'axe des x, elle représente le taux de faux positifs (1 - spécificité), tandis que sur l'axe des y, elle représente le taux de vrais positifs (sensibilité). 
                    <br>
                    <br>
                    Plus la courbe ROC est proche du coin supérieur gauche, meilleure est la performance du modèle.
                    <br>
                    <br>
                    Voici les graphiques permettant de visualiser la performance des différents modèles.
                    <div class="main-paragraph-radio">
                        <input type="radio" name="image_choice3" value="image5" id="image5" onclick="display_cloudWords()" checked> 
                        <label class="radio-style" for="image5">BERT ROC</label>
                        <input type="radio" name="image_choice3" value="image6" id="image6" onclick="display_cloudWords()">
                        <label class="radio-style" for="image6">roBERTa ROC</label>
                    </div>  
                    
                    <div class="main-paragraph-image">
                        <img src="../static/images/bert_ROC.png" alt="" id="main-paragraph-image-display_3">
                    </div>
                </div>
            </div>
          </div>

          <footer>
            <p>Tous droits réservés haDock404</p>
        </footer>
    </main>
</body>
</html>